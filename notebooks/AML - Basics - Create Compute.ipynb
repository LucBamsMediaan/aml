{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from aml.settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look [here](https://github.com/Azure/azureml-examples/tree/main) for way more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to a Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace. You can find the info on the workspace tab on ml.azure.com\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,  # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute\n",
    "\n",
    "Specify attributes in [.env file](../.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_or_update = False\n",
    "\n",
    "if COMPUTE_NAME in [com.name for com in ml_client.compute.list()]:\n",
    "    print(\n",
    "        f\"You already have a cluster named {COMPUTE_NAME}, we'll check whether its attributes match your specifications.\"\n",
    "    )\n",
    "    compute_target = ml_client.compute.get(COMPUTE_NAME)\n",
    "\n",
    "     # Check if the attributes of the existing compute match the specifications\n",
    "    differences = []\n",
    "    if compute_target.type != COMPUTE_TYPE:\n",
    "        differences.append(\"type\")\n",
    "    if compute_target.size.upper() != COMPUTE_SIZE.upper():\n",
    "        differences.append(\"size\")\n",
    "    if compute_target.min_instances != int(COMPUTE_MIN_INSTANCES):\n",
    "        differences.append(\"min_instances\")\n",
    "    if compute_target.max_instances != int(COMPUTE_MAX_INSTANCES):\n",
    "        differences.append(\"max_instances\")\n",
    "    if compute_target.idle_time_before_scale_down != float(COMPUTE_IDLE_TIME):\n",
    "        differences.append(\"idle_time_before_scale_down\")\n",
    "    if {\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier) != COMPUTE_TIER:\n",
    "        differences.append(\"tier\")\n",
    "        print({\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier), type({\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier)), COMPUTE_TIER)\n",
    "\n",
    "    # Print the differences, if any\n",
    "    if differences:\n",
    "        print(f\"The following attributes of compute target are different from your specifications: {', '.join(differences)}\")\n",
    "        create_or_update = True\n",
    "    else:\n",
    "        print(\"All attributes of compute_target match the specifications.\")\n",
    "else:\n",
    "    create_or_update = True\n",
    "\n",
    "if create_or_update:\n",
    "    user_input = input(\"-> Are you sure you want to create/update this Compute? [yes| no]: \")\n",
    "    print(f\"-> Are you sure you want to create/update this Compute? [yes| no]: {user_input.lower()}\")\n",
    "    \n",
    "    if user_input.upper() == \"YES\":\n",
    "        print(\"Creating/Updating compute target...\")\n",
    "        compute_target = AmlCompute(\n",
    "            name=COMPUTE_NAME,\n",
    "            type=COMPUTE_TYPE,\n",
    "            size=COMPUTE_SIZE,\n",
    "            min_instances=COMPUTE_MIN_INSTANCES,\n",
    "            max_instances=COMPUTE_MAX_INSTANCES,\n",
    "            idle_time_before_scale_down=COMPUTE_IDLE_TIME,\n",
    "            tier=COMPUTE_TIER,\n",
    "        )\n",
    "        compute_target = ml_client.begin_create_or_update(compute_target)\n",
    "        print(f\"AMLCompute with name {compute_target.name} is created/updated, the compute size is {compute_target.size}\")\n",
    "    else:\n",
    "        print(\"No compute target created/updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
