{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\PracticeProjects\\aml\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Tune - pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.entities import AmlCompute, Data, Environment, Model\n",
    "from azure.ai.ml.sweep import BanditPolicy, Uniform\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from aml.settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYMENOPTERA_DATA_PATH = \"data/hymenoptera\"\n",
    "HYMENOPTERA_DATA_NAME = \"hymenoptera\"\n",
    "HYMENOPTERA_DATA_DESCRIPTION = \"This dataset contains images of ants and bees intended for training a classification model. It consists of approximately 120 training images for each class (ants and bees) and 75 validation images for each class.\"\n",
    "\n",
    "HYMENOPTERA_MODEL_NAME=\"hymenoptera_model\"\n",
    "HYMENOPTERA_MODEL_DESCRIPTION=\"Model created for hymenoptera data.\"\n",
    "\n",
    "HYMENOPTERA_SWEEP_NAME=\"hymenoptera_sweep\"\n",
    "HYMENOPTERA_SWEER_DISPLAY_NAME=\"Hymenoptera Sweep\"\n",
    "HYMENOPTERA_SWEEP_DESCRIPTION=\"Sweep for training hymenoptera model.\"\n",
    "\n",
    "CURATED_ENV_NAME = \"AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu@latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace. You can find the info on the workspace tab on ml.azure.com\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,  # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset already exists. Name: hymenoptera, version: None\n"
     ]
    }
   ],
   "source": [
    "# Set the path, supported paths include:\n",
    "# local: './<path>/<folder>' (this will be automatically uploaded to cloud storage)\n",
    "# blob:  'wasbs://<container_name>@<account_name>.blob.core.windows.net/<path>/<folder>'\n",
    "# ADLS gen2: 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/<folder>'\n",
    "# Datastore: 'azureml://datastores/<data_store_name>/paths/<path>/<folder>'\n",
    "\n",
    "# Define the Data asset object\n",
    "my_data = Data(\n",
    "    path=HYMENOPTERA_DATA_PATH,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=HYMENOPTERA_DATA_DESCRIPTION,\n",
    "    name=HYMENOPTERA_DATA_NAME,\n",
    ")\n",
    "\n",
    "## create data asset if it doesn't already exist:\n",
    "try:\n",
    "    data_asset = ml_client.data.get(name=HYMENOPTERA_DATA_NAME, version=DATA_VERSION)\n",
    "    print(\n",
    "        f\"Data asset already exists. Name: {my_data.name}, version: {my_data.version}\"\n",
    "    )\n",
    "except:\n",
    "    ml_client.data.create_or_update(my_data)\n",
    "    data_asset = ml_client.data.get(name=HYMENOPTERA_DATA_NAME)\n",
    "    print(f\"Data asset created. Name: {my_data.name}, version: {my_data.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GPU cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named a100, we'll check whether its attributes match your specifications.\n",
      "All attributes of compute_target match the specifications.\n"
     ]
    }
   ],
   "source": [
    "create_or_update = False\n",
    "\n",
    "if GPU_NAME in [com.name for com in ml_client.compute.list()]:\n",
    "    print(\n",
    "        f\"You already have a cluster named {GPU_NAME}, we'll check whether its attributes match your specifications.\"\n",
    "    )\n",
    "    compute_target = ml_client.compute.get(GPU_NAME)\n",
    "\n",
    "     # Check if the attributes of the existing compute match the specifications\n",
    "    differences = []\n",
    "    if compute_target.type != GPU_TYPE:\n",
    "        differences.append(\"type\")\n",
    "    if compute_target.size.upper() != GPU_SIZE.upper():\n",
    "        differences.append(\"size\")\n",
    "    if compute_target.min_instances != int(GPU_MIN_INSTANCES):\n",
    "        differences.append(\"min_instances\")\n",
    "    if compute_target.max_instances != int(GPU_MAX_INSTANCES):\n",
    "        differences.append(\"max_instances\")\n",
    "    if compute_target.idle_time_before_scale_down != float(GPU_IDLE_TIME):\n",
    "        differences.append(\"idle_time_before_scale_down\")\n",
    "    if {\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier) != GPU_TIER:\n",
    "        differences.append(\"tier\")\n",
    "        print({\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier), type({\"low_priority\": \"LowPriority\", \"dedicated\": \"Dedicated\"}.get(compute_target.tier)), GPU_TIER)\n",
    "\n",
    "    # Print the differences, if any\n",
    "    if differences:\n",
    "        print(f\"The following attributes of compute target are different from your specifications: {', '.join(differences)}\")\n",
    "        create_or_update = True\n",
    "    else:\n",
    "        print(\"All attributes of compute_target match the specifications.\")\n",
    "else:\n",
    "    create_or_update = True\n",
    "\n",
    "if create_or_update:\n",
    "    user_input = input(\"-> Are you sure you want to create/update this Compute? [yes| no]: \")\n",
    "    print(f\"-> Are you sure you want to create/update this Compute? [yes| no]: {user_input.lower()}\")\n",
    "    \n",
    "    if user_input.upper() == \"YES\":\n",
    "        print(\"Creating/Updating compute target...\")\n",
    "        compute_target = AmlCompute(\n",
    "            name=GPU_NAME,\n",
    "            type=GPU_TYPE,\n",
    "            size=GPU_SIZE,\n",
    "            min_instances=GPU_MIN_INSTANCES,\n",
    "            max_instances=GPU_MAX_INSTANCES,\n",
    "            idle_time_before_scale_down=GPU_IDLE_TIME,\n",
    "            tier=GPU_TIER,\n",
    "        )\n",
    "        compute_target = ml_client.begin_create_or_update(compute_target)\n",
    "        print(f\"AMLCompute with name {compute_target.name} is created/updated, the compute size is {compute_target.size}\")\n",
    "    else:\n",
    "        print(\"No compute target created/updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the command job\n",
    "job = command(\n",
    "    inputs=dict(\n",
    "        # uri_file refers to a specific file as a data asset\n",
    "        data=Input(\n",
    "            path=data_asset.id,\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            mode=InputOutputModes.RO_MOUNT\n",
    "        ),\n",
    "        num_epochs=30,\n",
    "        learning_rate=0.001,\n",
    "        momentum=0.9,\n",
    "        output_dir=\"./outputs\",\n",
    "    ),\n",
    "    code=\"./src/train-tune-pytorch\",  # location of source code\n",
    "    # The inputs/outputs are accessible in the command via the ${{ ... }} notation\n",
    "    command=\"python pytorch_train.py --data ${{inputs.data}} --num_epochs ${{inputs.num_epochs}} --output_dir ${{inputs.output_dir}}\",\n",
    "    # This is the ready-made environment you are using\n",
    "    environment=CURATED_ENV_NAME,\n",
    "    # This is the compute you created earlier. You can alternatively remove this line to use serverless compute to run the job\n",
    "    compute=GPU_NAME,\n",
    "    # An experiment is a container for all the iterations one does on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    display_name=EXPERIMENT_DISPLAY_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading train-tune-pytorch (0.01 MBs): 100%|##########| 7342/7342 [00:00<00:00, 172641.49it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>hymenoptera_classification</td><td>tidy_shampoo_bdmqwzsdl7</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/tidy_shampoo_bdmqwzsdl7?wsid=/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourcegroups/DI_INTERNS/workspaces/di-internal-projects&amp;tid=1f6b76fa-8329-4164-9501-06e9eb8697fb\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'tidy_shampoo_bdmqwzsdl7', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/LucBamsMediaan/aml.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '1a679c08b8c05b6238f9f676faef0fc32d860cae', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'a100', 'ContentSnapshotId': '600b1984-d768-488d-8ae9-288a55508edc'}, 'print_as_yaml': False, 'id': '/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourceGroups/DI_INTERNS/providers/Microsoft.MachineLearningServices/workspaces/di-internal-projects/jobs/tidy_shampoo_bdmqwzsdl7', 'Resource__source_path': '', 'base_path': 'c:\\\\Workspace\\\\PracticeProjects\\\\aml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000025BF86ACA50>, 'serialize': <msrest.serialization.Serializer object at 0x0000025BF86C2990>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'hymenoptera classification', 'experiment_name': 'hymenoptera_classification', 'compute': 'a100', 'services': {'Tracking': {'endpoint': 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourceGroups/DI_INTERNS/providers/Microsoft.MachineLearningServices/workspaces/di-internal-projects?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/tidy_shampoo_bdmqwzsdl7?wsid=/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourcegroups/DI_INTERNS/workspaces/di-internal-projects&tid=1f6b76fa-8329-4164-9501-06e9eb8697fb', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_folder', 'path': 'hymenoptera:1', 'mode': 'ro_mount'}, 'num_epochs': '30', 'learning_rate': '0.001', 'momentum': '0.9', 'output_dir': './outputs'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.tidy_shampoo_bdmqwzsdl7', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000025BF81B0310>, 'num_epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000025BF81C3750>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000025BF86AD1D0>, 'momentum': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000025BF86AD950>, 'output_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000025BF82D5ED0>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000025BF866B190>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'tidy_shampoo_bdmqwzsdl7', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Workspace\\\\PracticeProjects\\\\aml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000025BF86ACA50>, 'serialize': <msrest.serialization.Serializer object at 0x0000025BF81B3790>, 'command': 'python pytorch_train.py --data ${{inputs.data}} --num_epochs ${{inputs.num_epochs}} --output_dir ${{inputs.output_dir}}', 'code': '/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourceGroups/DI_INTERNS/providers/Microsoft.MachineLearningServices/workspaces/di-internal-projects/codes/9eb317b7-4448-4a11-8862-83e5a57ad98c/versions/1', 'environment_variables': {}, 'environment': 'azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu@latest', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'hymenoptera classification', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_folder', 'path': '/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourceGroups/DI_INTERNS/providers/Microsoft.MachineLearningServices/workspaces/di-internal-projects/data/hymenoptera/versions/1', 'mode': 'ro_mount'}, 'num_epochs': {'type': 'string', 'default': '30'}, 'learning_rate': {'type': 'string', 'default': '0.001'}, 'momentum': {'type': 'string', 'default': '0.9'}, 'output_dir': {'type': 'string', 'default': './outputs'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.tidy_shampoo_bdmqwzsdl7', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourceGroups/DI_INTERNS/providers/Microsoft.MachineLearningServices/workspaces/di-internal-projects?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/tidy_shampoo_bdmqwzsdl7?wsid=/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourcegroups/DI_INTERNS/workspaces/di-internal-projects&tid=1f6b76fa-8329-4164-9501-06e9eb8697fb', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000025BF86ACA50>}, 'instance_id': '10c70076-c7ec-40f3-bb89-8fc128d5276f', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu@latest', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model hyperparameters\n",
    "\n",
    "Now that we've seen how to do a simple PyTorch training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's sweep capabilities.\n",
    "\n",
    "You will replace some of the parameters passed to the training job with special inputs from the azure.ml.sweep package â€“ that way, you are defining the parameter space in which to search.\n",
    "\n",
    "Since the training script uses a learning rate schedule to decay the learning rate every several epochs, you can tune the initial learning rate and the momentum parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will reuse the command_job created before. we call it as a function so that we can apply inputs\n",
    "job_for_sweep = job(\n",
    "    learning_rate=Uniform(min_value=0.0005, max_value=0.005),\n",
    "    momentum=Uniform(min_value=0.9, max_value=0.99),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you configure sweep on the command job, with some sweep-specific parameters like the primary metric to watch and the sampling algorithm to use.\n",
    "\n",
    "- You can use random sampling to try different configuration sets of hyperparameters to maximize the primary metric, the best validation accuracy (best_val_acc).\n",
    "- You can specify the early termination policy to use to early terminate poorly performing runs. Here you use the BanditPolicy, which will terminate any run that doesn't fall within the slack factor of our primary evaluation metric. You will apply this policy every epoch (since we report our `best_val_acc` metric every epoch and `evaluation_interval`=1). Notice we will delay the first policy evaluation until after the first 10 epochs (`delay_evaluation`=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_job = job_for_sweep.sweep(\n",
    "    compute=GPU_NAME,\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"best_val_acc\",\n",
    "    goal=\"Maximize\",\n",
    "    max_total_trials=4,\n",
    "    max_concurrent_trials=4,\n",
    "    early_termination_policy=BanditPolicy(\n",
    "        slack_factor=0.15, evaluation_interval=1, delay_evaluation=10\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = HYMENOPTERA_SWEER_DISPLAY_NAME\n",
    "sweep_job.experiment_name = HYMENOPTERA_SWEEP_NAME\n",
    "sweep_job.description = HYMENOPTERA_SWEEP_DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit this job as before. This will now run a sweep job that sweeps over our train job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: dreamy_wheel_c8dhz2t4p8\n",
      "Web View: https://ml.azure.com/runs/dreamy_wheel_c8dhz2t4p8?wsid=/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourcegroups/DI_INTERNS/workspaces/di-internal-projects\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2024-04-26T08:55:22.131638][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n",
      "[2024-04-26T08:55:22.6385544Z][SCHEDULER][INFO]Scheduling job, id='dreamy_wheel_c8dhz2t4p8_0' \n",
      "[2024-04-26T08:55:22.7600954Z][SCHEDULER][INFO]Scheduling job, id='dreamy_wheel_c8dhz2t4p8_1' \n",
      "[2024-04-26T08:55:22.8594118Z][SCHEDULER][INFO]Scheduling job, id='dreamy_wheel_c8dhz2t4p8_2' \n",
      "[2024-04-26T08:55:22.9763452Z][SCHEDULER][INFO]Scheduling job, id='dreamy_wheel_c8dhz2t4p8_3' \n",
      "[2024-04-26T08:55:22.941921][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n",
      "[2024-04-26T08:55:23.2851255Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dreamy_wheel_c8dhz2t4p8_0' \n",
      "[2024-04-26T08:55:23.3682406Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dreamy_wheel_c8dhz2t4p8_1' \n",
      "[2024-04-26T08:55:23.3386273Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dreamy_wheel_c8dhz2t4p8_3' \n",
      "[2024-04-26T08:55:23.3935769Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dreamy_wheel_c8dhz2t4p8_2' \n",
      "[2024-04-26T08:55:52.178178][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\n",
      "[2024-04-26T08:55:52.382799][GENERATOR][INFO]All jobs generated.\n",
      "[2024-04-26T09:00:55.2951385Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: dreamy_wheel_c8dhz2t4p8\n",
      "Web View: https://ml.azure.com/runs/dreamy_wheel_c8dhz2t4p8?wsid=/subscriptions/66ac1049-5712-45db-ac73-0472ab01abf8/resourcegroups/DI_INTERNS/workspaces/di-internal-projects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# stream the output and wait until the job is finished\n",
    "ml_client.jobs.stream(returned_sweep_job.name)\n",
    "\n",
    "# refresh the latest status of the job after streaming\n",
    "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the job using the studio UI link presented when you run the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best model\n",
    "\n",
    "**Once all the runs complete**, you can find the run that produced the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if returned_sweep_job.status == \"Completed\":\n",
    "\n",
    "    # First let us get the run which gave us the best result\n",
    "    best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
    "\n",
    "    # lets get the model from this run\n",
    "    model = Model(\n",
    "        # the script stores the model as \"outputs\"\n",
    "        path=\"azureml://jobs/{}/outputs/artifacts/paths/outputs/\".format(best_run),\n",
    "        name=HYMENOPTERA_MODEL_NAME,\n",
    "        description=HYMENOPTERA_MODEL_DESCRIPTION,\n",
    "        type=\"custom_model\",\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Sweep job status: {}. Please wait until it completes\".format(\n",
    "            returned_sweep_job.status\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
